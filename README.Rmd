---
title: "BayesMultiMode"
output: github_document
bibliography: inst/REFERENCES.bib
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  dpi=600,
  fig.path = "man/figures/README-"
)
```

<!-- badges: start -->
[![R-CMD-check](https://github.com/paullabonne/BayesMultiMode/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/paullabonne/BayesMultiMode/actions/workflows/R-CMD-check.yaml)
[![CRAN_Status_Badge](https://www.r-pkg.org/badges/version/BayesMultiMode)](https://cran.r-project.org/package=BayesMultiMode)
<!-- badges: end -->

`BayesMultiMode` is an R package for detecting and exploring multimodality using Bayesian techniques. The approach works in two stages. First, a mixture distribution is fitted on the data using a sparse finite mixture Markov chain Monte Carlo (SFM MCMC) algorithm. The number of mixture components does not have to be known; the size of the mixture is estimated endogenously through the SFM approach. Second, the modes of the estimated mixture at each MCMC are retrieved using algorithms specifically tailored for mode detection. These estimates are then used to construct posterior probabilities for the number of modes, their locations and uncertainties, providing a powerful tool for mode inference. 

### Installing BayesMultiMode from CRAN
```{r, eval = FALSE}
install.packages("BayesMultiMode")
```

### Or installing the development version from GitHub
```{r, eval = FALSE}
# install.packages("devtools") # if devtools is not installed 
devtools::install_github("paullabonne/BayesMultiMode")
```

### Loading BayesMultiMode
```{r}
library(BayesMultiMode)
```

### Using BayesMultiMode for both MCMC estimation and mode inference
`BayesMultiMode` provides a very flexible and efficient MCMC estimation approach : it handles mixtures with unknown number of components through the sparse finite mixture approach of @malsiner-walli_model-based_2016 and supports a comprehensive range of mixture distributions, both continuous and discrete.

#### Estimation
```{r, out.width = '70%', fig.align = "center"}
set.seed(123)

# retrieve galaxy data
y = galaxy

# estimation
bayesmix = bayes_estimation(data = y,
                            K = 10,
                            dist = "normal",
                            nb_iter = 2000,
                            burnin = 1000)

# plot estimated mixture
plot(bayesmix, max_size = 200)
```

#### Mode inference
```{r, out.width = '70%', fig.align = "center"}
# mode estimation
bayesmode = bayes_mode(bayesmix)

# plot 
plot(bayesmode, max_size = 200)

# Summary 
summary(bayesmode)
```

### Using BayesMultiMode for mode inference with external MCMC output
`BayesMultiMode` also works on MCMC output generated using external software. The function `new_BayesMixture()` creates an object of class `BayesMixture` which can then be used as input in the mode inference function `bayes_mode()`. Here is an example using cyclone intensity data [@knapp_international_2018] and the `BNPmix` package for estimation.
```{r, out.width = '70%', fig.align = "center"}
library(BNPmix)
library(dplyr)

y = cyclone %>%
  filter(BASIN == "SI",
         SEASON > "1981") %>%
  select(max_wind) %>%
  unlist()

## estimation
PY_result = PYdensity(y,
                      mcmc = list(niter = 2000, nburn = 1000),
                      output = list(out_param = TRUE))
```

#### Transforming the output into a mcmc matrix with one column per variable
```{r, message = FALSE}
library(dplyr)

mcmc_py = list()

for (i in 1:length(PY_result$p)) {
  k = length(PY_result$p[[i]][, 1])
  
  draw = c(PY_result$p[[i]][, 1],
           PY_result$mean[[i]][, 1],
           sqrt(PY_result$sigma2[[i]][, 1]),
           i)
  
  names(draw)[1:k] = paste0("eta", 1:k)
  names(draw)[(k+1):(2*k)] = paste0("mu", 1:k)
  names(draw)[(2*k+1):(3*k)] = paste0("sigma", 1:k)
  names(draw)[3*k + 1] = "draw"
  
  mcmc_py[[i]] = draw
}

mcmc_py = bind_rows(mcmc_py)
```

#### Creating an object of class `BayesMixture`
```{r}
pars_names = c(eta = "eta",
               mu = "mu",
               sigma = "sigma")

py_BayesMix = new_BayesMixture(mcmc = mcmc_py,
                               data = y,
                               K = (ncol(mcmc_py)-1)/3,
                               burnin = 0, # the burnin has already been discarded
                               dist = "normal",
                               pars_names = pars_names,
                               dist_type = "continuous")
```

#### Plotting the mixture
```{r, out.width = '70%', fig.align = "center"}
plot(py_BayesMix)
```

#### Mode inference
```{r, out.width = '70%', fig.align = "center"}
# mode estimation
bayesmode = bayes_mode(py_BayesMix)

# plot Â¨
plot(bayesmode, max_size = 200)

# Summary 
summary(bayesmode)
```


### References
