% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mix_mode.R
\name{mix_mode}
\alias{mix_mode}
\title{Find modes of mixtures}
\usage{
mix_mode(
  mixture,
  tol_mixp = 1e-06,
  tol_x = 1e-06,
  tol_conv = 1e-08,
  type = "all"
)
}
\arguments{
\item{mixture}{An object of class \code{Mixture} generated with \code{new_Mixture()}.}

\item{tol_mixp}{Components with a mixture proportion below tol_mixp are discarded when estimating modes; default is 1e-2.}

\item{tol_x}{(for continuous mixtures) Tolerance parameter for distance in-between modes; default is 1e-6; if two modes are closer than \code{tol_x}, only the first estimated mode is kept.}

\item{tol_conv}{(for continuous mixtures) Tolerance parameter for convergence of the algorithm; default is 1e-8.}

\item{type}{(for discrete mixtures) Type of modes, either unique or all (the latter includes flat modes); default is "all".}
}
\value{
An object of class Mode.
}
\description{
This function estimate modes in univariate mixture distributions.
The fixed-point algorithm of Carreira-Perpinan (2000) is used for Gaussian mixtures.
The Modal EM algorithm of Li et al. (2007) is used for other continuous mixtures.
A basic algorithm is used for discrete mixtures (see Cross et al. 2023).
}
\details{
This function finds modes in a univariate mixture defined as:
\deqn{p(.) = \sum_{k=1}^{K}\pi_k p_k(.),}
where \eqn{p_k} is a density or probability mass function.

\cr\cr
Fixed-point algorithm\cr
Following Carreira-perpinan (2000), a mode \eqn{x} is found by iterating the two steps:
\deqn{(i) \quad p(k|x^{(n)}) = \frac{\pi_k p_k(x^{(n)})}{p(x^{(n)})},}
\deqn{(ii) \quad x^{(n+1)} = f(x^{(n)}),}
with
\deqn{f(x) = (\sum_k p(k|x) \sigma_k)^{-1}\sum_k p(k|x) \sigma_k \mu_k,}
until convergence, that is, until \eqn{abs(x^{(n+1)}-x^{(n)})< \text{tol}_\text{conv}},
where \eqn{\text{tol}_\text{conv}} is an argument with default value \eqn{1e-8}.
Following Carreira-perpinan (2000), the algorithm is started at each component location.
Separately, it is necessary to identify identical modes which diverge only up to
a small value. By default modes which are closer
than \eqn{sd(y)/10} are merged; this tolerance value can be controlled with the argument
\code{tol_x}.

\cr\cr
MEM algorithm\cr
Following Li and Lindsay (2007), a mode \eqn{x} is found by iterating the two steps:
\deqn{(i) \quad p(k|x^{(n)}) = \frac{\pi_k p_k(x^{(n)})}{p(x^{(n)})},}
\deqn{(ii) \quad x^{(n+1)} = \text{argmax}_x  \sum_k p(k|x) \text{log} p_k(x^{(n)}),}
until convergence, that is, until \eqn{abs(x^{(n+1)}-x^{(n)})< \text{tol}_\text{conv}},
where \eqn{\text{tol}_\text{conv}} is an argument with default value \eqn{1e-8}.
The algorithm is started at each component location.
Separately, it is necessary to identify identical modes which diverge only up to
a small value. By default modes which are closer
than \eqn{sd(y)/10} are merged; this tolerance value can be controlled with the argument
\code{tol_x}.

\cr\cr
Discrete method\cr
By definition, modes must satisfy either: 
 \deqn{p_k(y_{m}-1) < p_k(y_{m}) > p_k(y_{m}+1)};
 \deqn{p_k(y_{m}-1) < p_k(y_{m}) = p_k(y_{m}+1) = \ldots = p_k(y_{m}+l-1) > p_k(y_{m}+l).}
 
 The algorithm evaluate each location point with these two conditions.
}
\examples{

# Example with a normal distribution ====================================
mu = c(0,5)
sigma = c(1,2)
p = c(0.5,0.5)

params = c(eta = p, mu = mu, sigma = sigma)
mix = new_Mixture(params, dist = "normal")
modes = mix_mode(mix)

# summary(modes)
# plot(modes)

# Example with a skew normal =============================================
xi = c(0,6)
omega = c(1,2)
alpha = c(0,0)
p = c(0.8,0.2)
params = c(eta = p, xi = xi, omega = omega, alpha = alpha)
dist = "skew_normal"

mix = new_Mixture(params, dist = dist)
modes = mix_mode(mix)
# summary(modes)
# plot(modes)

# Example with an arbitrary continuous distribution ======================
xi = c(0,6)
omega = c(1,2)
alpha = c(0,0)
nu = c(3,100)
p = c(0.8,0.2)
params = c(eta = p, mu = xi, sigma = omega, xi = alpha, nu = nu)

pdf_func <- function(x, pars) {
  sn::dst(x, pars["mu"], pars["sigma"], pars["xi"], pars["nu"])
}

mix = new_Mixture(params, pdf_func = pdf_func,
dist_type = "continuous", loc = "mu")
modes = mix_mode(mix)

# summary(modes)
# plot(modes, from = -4, to = 4)

# Example with a poisson distribution ====================================
lambda = c(0.1,10)
p = c(0.5,0.5)
params = c(eta = p, lambda = lambda)
dist = "poisson"


mix = new_Mixture(params, range = c(0,50), dist = dist)

modes = mix_mode(mix)

# summary(modes)
# plot(modes, from = 0, to = 20)

# Example with an arbitrary discrete distribution =======================
mu = c(20,5)
size = c(20,0.5)
p = c(0.5,0.5)
params = c(eta = p, mu = mu, size = size)


pmf_func <- function(x, pars) {
  dnbinom(x, mu = pars["mu"], size = pars["size"])
}

mix = new_Mixture(params, range = c(0, 50),
pdf_func = pmf_func, dist_type = "discrete")
modes = mix_mode(mix)

# summary(modes)
# plot(modes, from = 0, to = 50)

}
\references{
\insertRef{cross_2023}{BayesMultiMode}

\insertRef{li_nonparametric_2007}{BayesMultiMode}\cr\cr
\insertRef{carreira-perpinan_mode-finding_2000}{BayesMultiMode}
\insertRef{schaap_genome-wide_2013}{BayesMultiMode}
}
